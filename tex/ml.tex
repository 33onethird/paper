\section{Machine Learning}
This section will detail our approach to classify Android apps into malware and benignware. We will utilize Machine Learning for this task. Specifically, we expand upon the Machine Learning systems introduced in \cite{drebin} and \cite{7917369}. 
Obviously, we need training data for our classifier. We use two datasets: the Drebin dataset used in \cite{drebin} and another dataset that we were provided with by IKARUS Security Software GmbH\footnote{https://www.ikarussecurity.com/} (henceforth referred to as \emph{Ikarus dataset}). The Drebin dataset contains $123,453$ benignware samples and $5560$ malware samples. The Ikarus dataset contains $29,148$ benignware samples and $29,627$ samples. It additionally supplies $29,774$ adware samples, which we ignore in our analysis.

When comparing the two datasets, one sees that the Drebin dataset displays a significant class imbalance of around 1:22. On the other hand, the Drebin dataset supplies more total observations. It is also important to note that the Drebin dataset contains Android apps published before 2014, while the Ikarus dataset contains Android apps published in 2017. It is clear that the Ikarus dataset is more suitable to the classification. We use both dataset to reproduce the results of \cite{drebin} and compare the two approaches.

The dataset consists solely of binary features (see \Cref{sec:fe}). The label is also binary (0: benignware, 1: malware). The Drebin dataset provides a $545334$-dimensional feature space, while the Ikarus dataset provides a $ToDo$-dimensional feature space.

The classification system detailed in \cite{drebin} utilizes the linear SVM algorithm. This poses an issue, since the linear SVM assumes real-valued inputs. The assumption holds in our case, but it does not utilize the binary nature of our inputs. Therefore, we additionally use three other algorithms which utilize categorical features and labels: \emph{Bernoulli Naive Bayes}, \emph{Logistic Regression} and \emph{Random Forests}. Bernoulli Naive Bayes mainly serves as robust baseline.

We also implemented a neural network for classification. We used a \emph{multi-layer perceptron} (MLP), beause the local connectivity of \emph{convolutional neural networks} (CNN) and the memory capabilities of \emph{recurrent neural networks} (RNN) were contrary to our assumptions. The MLP could improve the classifications due to two capabilities: learning low-dimensional representations of apps and detecting feature hierarchies. Due to lack of resources, we were not able to validate this assumption.