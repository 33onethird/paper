\section{Machine Learning}
This section will detail our approach to classify Android apps into malware and benignware. We utilize Machine Learning methods for this task. Specifically, we expand upon the Machine Learning systems introduced in \cite{drebin} and \cite{7917369}.

Obviously, we need training data for our classifier. We use two datasets: the Drebin dataset used in \cite{drebin} and another dataset that we were provided with by IKARUS Security Software GmbH\footnote{\url{https://www.ikarussecurity.com}} (henceforth referred to as \emph{Ikarus dataset}). The Drebin dataset contains 123,453 benignware samples and 5,560 malware samples. The Ikarus dataset contains 29,148 benignware samples and 29,627 malware samples. Additionaly, it supplies 29,774 adware samples and 29,957 unlabeled samples, which we ignore in our analysis.

When comparing the two datasets, one sees that the Drebin dataset displays a significant class imbalance of around 1:22. On the other hand, the Drebin dataset supplies more total observations. It is also important to note that the Drebin dataset contains Android apps published before 2014, while the Ikarus dataset contains Android apps published in 2017. It is clear that the Ikarus dataset is generally more suitable to the classification task. We use both datasets to reproduce the results of \cite{drebin} and compare the two approaches.

The dataset consists solely of binary features (see \Cref{sec:fe}). The label is also binary (0: benignware, 1: malware). The Drebin dataset provides a 545,334-dimensional feature space, while the Ikarus dataset provides a 316,256-dimensional feature space.

The classification system detailed in \cite{drebin} utilizes the linear SVM algorithm. This poses an issue, since the linear SVM assumes real-valued inputs. The assumption holds in our case, but it does not utilize the binary nature of our features. Therefore, we additionally use three other algorithms which utilize categorical features and labels: \emph{Bernoulli Naive Bayes} \cite{Manning:2008:IIR:1394399}, \emph{Logistic Regression} \cite{10.2307/2983890} and \emph{Random Forests} \cite{598994}. Bernoulli Naive Bayes mainly serves as robust baseline.

We also implemented a neural network for classification. We used a \emph{multi-layer perceptron} (MLP) \cite{rosenblatt1958}, beause the local connectivity of \emph{convolutional neural networks} (CNN) \cite{Fukushima1980} and the memory capabilities of \emph{recurrent neural networks} (RNN) \cite{doi:10.1162/neco.1997.9.8.1735} were contrary to our assumptions. We figure that the MLP could improve the classifications due to two capabilities: learning low-dimensional representations of apps and detecting feature hierarchies. Due to lack of resources, we were not able to validate this assumption.